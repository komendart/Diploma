\subsection{Идея приближения}

Сейчас у нас запросы на отрезках и при подсчете их веса берется количество посещенных вершин. Давайте решать похожую задачу. Заменим запрос $[L, R]$ на два запроса $[1, R]$ и $[L, n]$ с весами, равными весу исходного запроса

Будем в такой задаче считать весом дерева отрезков сумму по всем новым запросам веса запроса умножить на максимальную глубину посещенной им вершины.
Здесь глубину корня считаем равной единице, а глубина любой другой вершины выражается как глубина её непосредственного предка плюс один.

\subsection{Доказательство ухудшения не более чем в константу раз}

Посмотрим, какие вершины запрос $[1, R]$ посещает, начиная с корня. Если сейчас он находится в вершине, соответствующей отрезку $[x, R]$, то дальше он не спускается. Пусть иначе правый сын не посещается, тогда запрос спускается в левого сына. Если правый сын посещается, то посещается и левый, но отрезок левого сына обязан лежать целиком в $[1, R]$, поэтому дальше левого сына спуск не идёт, и запрос спускается в правого сына.

В итоге, запрос приходит только в наименее глубокую вершину с правой границей $R$. Так как на каждом шаге либо запрос посещает одного сына, либо спускается в другого сына максимум на одну вершину, то более глубоких вершин запрос не посетит.

Отсюда следуют два утверждения:

\begin{itemize}
    \item \textbf{Утверждение:} Самая глубокая вершина, которую посещает запрос $[1, R]$ соответствует отрезку $[x, R]$ для некоторого $x$, причём если таких вершин несколько, то соответствует наименее глубокой из них.
    \item \textbf{Утверждение:} Запрос $[1, R]$ на каждой глубине посещает не более двух вершин.
\end{itemize}

Аналогично доказываются симметричные утверждения:

\begin{itemize}
    \item \textbf{Утверждение:} Самая глубокая вершина, которую посещает запрос $[L, n]$ соответствует отрезку $[L, x]$ для некоторого $x$, причём если таких вершин несколько, то соответствует наименее глубокой из них.
    \item \textbf{Утверждение:} Запрос $[L, n]$ на каждой глубине посещает не более двух вершин.
\end{itemize}

Давайте смотреть, как соотносится количество посещенных вершин исходного запроса $[L, R]$ и сумма глубин двух новых запросов $[1, R]$ и $[L, n]$.

\begin{itemize}
    \item \textbf{Первый случай} - исходный запрос начинает в корне и затем спускается ровно в одного сына текущей вершины, либо заканчивает работу.
    
    Заметим, что закончить работу он может только в вершине, которая соответствует отрезку $[L, R]$
    Непосредственный предок этой вершины имеет ровно одну отличающуюся границу отрезка. Следовательно,
    один из запросов $[1, R]$ и $[L, n]$ заканчивается там же, где и исходный запрос, а другой заканчивается раньше.
    Следовательно, сумма глубин новых запросов больше или равна и не более чем в два раза больше чем количество
    посещенных вершин исходного запроса
  
  
    \item \textbf{Второй случай} - исходный запрос сначала спускается ровно в одного сына текущей вершины, потом в вершине,
    у которой либо левая, либо правая граница совпадает с соответствующими границами $[L, R]$ переходит в обоих
    сыновей.
    
    Не теряя общности, что запрос разветвляется в вершине - отрезке $[L, x]$, где $x > R$.
    Тогда в правом сыне будет отрезок $[m + 1, x]$, где $m + 1 \le R$, так как иначе правого сына запрос бы
    не посетил. Но тогда в левом сыне будет отрезок $[L, m]$, целиком лежащий в $[L, R]$,
    поэтому в левом сыне будет посещена ровно одна вершина.
    
    В правом сыне $[m + 1, x]$ запрос $[L, R]$ будет действовать аналогично запросу $[1, R]$ на всём
    дереве отрезков. То есть на каждой глубине будет посещено не более двух вершин и самая глубокая вершина совпадает с самой глубокой вершиной для $[1, R]$
    
    Обозначим за $d_{lca}$ глубину вершины, где происходит разветвление, за $d_R$ разность между глубинами самой глубокой вершины $[1, R]$ и $d_{lca}$.
    
    Глубина запроса $[L, n]$ не превосходит $d_{lca}$. Глубина запроса $[1, R]$ равна $d_{lca} + d_R$. 
    Сумма этих глубин лежит в отрезке $[d_{lca} + 1 + d_R; 2d_{lca} + d_R]$. Количество посещенных вершин запросом $[L, R]$ лежит в отрезке $[d_{lca} + 1 + d_R; d_{lca} + 1 + 2d_R]$
    
    Следовательно, сумма глубин запросов может не более чем в два раза превосходить количество посещенных вершин и так же может не более чем в два раза уступать количеству посещенных вершин.
    
    
    \item \textbf{Третий случай} - исходный запрос сначала спускается ровно в одного сына текущей вершины, потом
    переходит в обоих сыновей и в этой вершины и левая, и правая граница отличается от соответствующей границы $[L, R]$.
    
    Пусть в вершине с разветвлением отрезок $[a, b]$. Тогда в левом сыне отрезок $[a, m]$, в правом $[m + 1, b]$ для некоторого $m$.
    
    Так как $a \ne L, b \ne R$, то дальше запрос на $[a, m]$ ведёт себя так же как и запрос $[L, n]$, на $[m + 1, R]$ как запрос $[1, R]$
    
    Обозначим за $d_{lca}$ глубину вершины, где происходит разветвление, за $d_L$ разность между глубинами самой глубокой вершины $[L, n]$ и $d_{lca}$, за $d_R$ разность между глубинами самой глубокой вершины $[1, R]$ и $d_{lca}$.
    
    Тогда глубина запроса $[L, n]$ равна $d_{lca} + d_L$, запроса $[1, R]$ равна $d_{lca} + d_R$. Сумма этих двух значений $2d_{lca} + d_L + d_R$.
    Количество посещенных вершин аналогично предыдущему случаю лежит на отрезке $[d_{lca} + (d_L + d_R); d_{lca} + 2(d_L + d_R)]$
    
    Следовательно, сумма глубин запросов может не более чем в два раза превосходить количество посещенных вершин и также может не более чем в два раза уступать количеству посещенных вершин.

\end{itemize}    

После разбора случаев становится ясно, что вес всего дерева отрезков на новых запросах может отличаться не более чем в два раза в обе стороны от веса дерева отрезков на старых запросах. Тогда в худшем случае оптимальное на новых запросах дерево отрезков может быть хуже не более чем в четыре раза на старых запросах, чем соответствующее оптимальное дерево.


\subsection{Алгоритм нахождения приближенного решения}

Повторим доказанные ранее утверждения

\textbf{Утверждение:} Самая глубокая вершина, которую посещает запрос $[1, R]$ соответствует отрезку $[x, R]$ для некоторого $x$, причём если таких вершин несколько, то соответствует наименее глубокой из них.

\textbf{Утверждение:} Самая глубокая вершина, которую посещает запрос $[L, n]$ соответствует отрезку $[L, x]$ для некоторого $x$, причём если таких вершин несколько, то соответствует наименее глубокой из них.

Если мы можем определить, как выбирать самую глубокую вершину, то можно так же и определить, как выбирать путь до этой вершины (не включающий эту вершину).

Пусть в дереве отрезков есть вершина $v_{[L, R]}$, соответствующая отрезку $[L, R]$. Скажем, что стоимость отрезка $[L, R]$ - это сумма по всем новым запросам их веса помножить на количество вершин из пути до самой глубокой вершины, которые лежат в поддереве $v_{[L, R]}$. Тогда $dp_{L, R}$ - это минимальная стоимость отрезка $[L, R]$ среди всех возможных разбиений этого отрезка на поддерево.

Заметим, что итоговая стоимость стоимость отрезка $[1, n]$ отличается от введенного ранее веса дерева отрезков на сумму весов всех запросов (так как не учитывается самая глубокая вершина). Это константа, не зависящая от вида дерева, поэтому неучитывание самой глубокой вершины запроса не влияет на оптимальность.

Введём вспомогательные величины
\begin{itemize}
    \item $lw_i$ - сумма весов всех запросов $[i, n]$
    \item $rw_i$ - сумма весов всех запросов $[1, i]$
\end{itemize}

Теперь можно описать как считать $dp_{L, R}$

\begin{itemize}
    \item $dp_{L, L} = 0$ (так как только самая глубокая вершина может попасть в лист дерева отрезков,
    а её мы не учитываем)
    \item $dp_{L, R} = \sum \limits_{i = L + 1}^R lw_i + \sum \limits_{i = L}^{R - 1} rw_i
    + \min \limits_{L \leqslant m < R} {dp_{L, m} + dp_{m + 1, R}}$
    
    Для запросов $[x, n]$, где $x$ не лежит в $[L, R]$ самая глубокая вершина просто не лежит в поддереве $v_{[L, R]}$.
    Если $x = L$, то лежать в поддереве может только самая глубокая вершина, но не вершины из пути до неё. Для всех     остальных запросов добраться до вершины с левой границей $x$ можно только пройдя через $v_{[L, R]}$, поэтому их     веса мы прибавляем.
    Аналогичны рассуждения про то, какие запросы $[1, x]$ нужно учитывать.
\end{itemize}

Введём $w_i = rw_i + lw_{i + 1}$ для $i \in \{1,\dots,n-1\}$

Тогда $dp_{L, R} = \sum \limits_{i = L}^{R - 1} w_i + \min \limits_{L \leqslant m < R} {dp_{L, m} + dp_{m + 1, R}}$

В чём смысл данного выражения? Все $w_i$ от $L$ до $R - 1$ учитываются в $dp_{L, R}$. После этого выбирается оптимальное $m$ такое, что все $w_i$ с $i < m$ идут влево, все с $i > m$ идут вправо, $w_m$ больше нигде не учитывается.

Но тогда $dp_{L, R}$ соответствует весу статически оптимального дерева поиска, где вероятности запроса элемента пропорциональны $w_L,\dots, w_{R-1}$, а вероятности запросов между двух элементов дерева равна нулю.

Эта задача уже хорошо изучена. Как упомянуто в обзоре литературы, её можно решать точно за $O(n^2)$ и приближенно за $O(n)$.

В итоге получаем решение, которое работает за $O(n + S)$ времени. Ухудшение может вносить как первоначальное приближение, так и приближение нахождения дерева поиска. В итоге решение хуже оптимального не более в чем константу раз, где константу сверху можно оценить как $4$ умножить на константу приближения дерева поиска $\approx 4 \cdot 2.29 = 9.16$

\subsection{Изучение поведения на реальных тестах}

Решение выше асимптотически оптимально, поэтому уже представляет теоретический интерес. Тем не менее, доказанная константа слишком велика для практического применения.

Я написал приближенное решения за $O(n + S)$ (использующее приближенное решения для статически оптимального дерева поиска) и за $O(n^2 + S)$ (использующее точное решение) и сравнивал с оптимальным результатом, полученным с помощью точного решения за $O(n^3 + S)$.

Я рассматривал несколько вариантов с $n$ от единицы до сотни и количеством отрезков $S$ от меньше десятка до $n^2$. Для фиксированных $n$ и $S$ я прогонял большое количество тестов, генерируя границы запросов и их веса равномерно случайно.

$n > 100$ не рассматривались, так как

\begin{itemize}
    \item На каждый тест запускалось точное решение за $O(n^3 + S)$, при этом для большей достоверности хотелось бы запустить как можно больше тестов.
    \item Есть подозрение, что среди больших случайных тестов вероятность плохого теста для приближенного решения крайне мала.
\end{itemize}

На всех таких случайных тестах я получил такие результаты:

\begin{itemize}
    \item Решение за $O(n^2 + S)$ находит
    дерево отрезков с весом хуже не более чем в $\approx 1.42$ раз чем оптимальное
    \item Решение за $O(n + S)$ находит
    дерево отрезков с весом хуже не более чем в $\approx 2.3$ раз чем оптимальное
\end{itemize}

Это гораздо лучше чем доказанные константы и выглядит уже как что-то, что можно применить на практике. В частности константа для решения за $O(n + S)$ близка к константе у приближенного алгоритма для нахождения статически оптимального дерева поиска.